<!-- saved from url=(0025)https://www.mit.edu/~jda/ -->
<html>

<head lang="en">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Lio Wong | Stanford</title>
    <link rel="stylesheet" type="text/css" href="academic_stylesheet.css">
    <link rel="icon" href="favicon.ico">
</head>

<body>
    <div class="content">
        <name>lio wong</name>
        <img class="margin" src="images/LioWong_profile.png" width="100%">

        <p>
            I am currently a <a href="https://hai.stanford.edu/research/fellowship-programs"> Stanford Human-Centered Artificial Intelligence</a> Postdoctoral Fellow working with the <a
                href="https://cogtoolslab.github.io/">Cognitive Tools Lab</a>. I also maintain affiliations with the <a href="https://cocosci.mit.edu/"> Computational Cognitive Science</a> and <a
                href="https://lingo.csail.mit.edu/"> LINGO</a> labs at MIT. I completed my PhD at MIT in Brain and Cognitive Sciences in 2025, advised by Josh Tenenbaum and Jacob Andreas. I received
            my B.S. and M.S. in computer science at Stanford, advised by Dan Jurafsky and
            Sebastian Thrun.
        </p>

        <p>
            My research asks how people <strong>understand and learn from language</strong>. How do human minds represent and <strong>construct meaning</strong> from language â€” how do we usefully
            relate
            words and sentences to everything else that we know and believe? And how do people <strong>learn so much from language</strong>, including new concepts and theories that might dramatically
            change how we understand the world around them? I'm particularly interested in understanding how people manage to learn, understand, and usefully reason about language with <i>so much less
                language experience</i> and
            <i>way fewer computational resources</i> than any of our current best computational models.

        </p>

        <p>
            My work seeks to answer these questions by combining theory-driven cognitive experiments with formal computational tools, including <i>structured probabilistic models of cognition, program
                synthesis, and machine learning approaches </i>. I look for approaches that can scale our theoretical and empirical picture of how we understand and learn from
            language,
            both by explaining how language relates to other domains of psychology (like intuitive physical or social cognition) and how we can unify disparate formal approaches to modeling language
            (like those from linguistics, cognitive science, and AI). Iâ€™m also a writer. I love
            a heady and intimate sentence, and would like to build models that explain even a sliver of what
            we get out of ones as rich and unruly as <a href="https://app.simplenote.com/publish/Zyr2yb">these</a>.
        </p>

        <p>
            I use they/them pronouns. Earlier publications appear under the name Catherine Wong ðŸ’¯.
        </p>

        <p style="text-align:center">
            <a href="mailto:liowong@stanford.edu">liowong@stanford.edu</a> &nbsp/&nbsp
            <!-- <a href="data/Catherine_Wong_cv.pdf">CV</a> &nbsp/&nbsp -->
            <a href="https://scholar.google.com/citations?user=KssJcIAAAAAJ&hl=en">Google Scholar</a>
            &nbsp/&nbsp
            <a href="https://github.com/CatherineWong?tab=repositories">Github</a>
            &nbsp/&nbsp
            <a href="https://web.mit.edu/zyzzyva/www/">writing and clocks</a> &nbsp/&nbsp
            <a href="https://signalhill.fm/">signal hill</a>
        </p>

        <br>
        <h2>Research Areas</h2>

        <div class="highlight">
            <h4 style="margin:0em">How do we understand language with so little language experience?</h4>
            <ul style="padding-left:1em">
                <li style="margin-bottom: 3px;"><b><i>From words to worlds: bridging language and thought</i></b>. [<a
                        href="https://dspace.mit.edu/bitstream/handle/1721.1/157326/wong-zyzzyva-phd-bcs-2024-thesis.pdf?sequence=1&isAllowed=y">Thesis, 2024</a>][<a
                        href="https://arxiv.org/abs/2306.12672">SPP, 2023</a>] <br>[<a
                        href="https://underline.io/events/489/sessions/20498/lecture/123945-from-words-to-world-bridging-language-and-thought">Glushko Dissertation Talk @ CogSci</a>]

                    [<a href="https://simons.berkeley.edu/talks/lio-wong-mit-alex-lew-mit-2023-08-17">Simons Talk @
                        Berkeley</a>]
                </li>

                <li>
                    How do people understand language about someone's <i>knowledge and beliefs</i>? [<a href="https://arxiv.org/pdf/2408.12022">NAACL, 2025</a>]
                </li>

                <li>How do people understand language about <i>physical scenes and events</i>? [<a href="https://escholarship.org/content/qt7018f2ss/qt7018f2ss.pdf">CogSci, 2023</a>]
                </li>



                <li>How do people understand language about <i>actions and goals</i>? [<a href="https://arxiv.org/pdf/2306.14325.pdf">ICML Theory of Mind, 2023</a>]
                </li>

                <li>How do people understand <i>vague adjectives</i> in context? [<a href="https://arxiv.org/pdf/2305.01020.pdf">CogSci,
                        2023</a>]
                </li>
            </ul>
        </div>


        <div class="highlight">
            <h4 style="margin:0em">How do we understand language (and reason in general) with so few computational resources?</h4>
            <ul style="padding-left:1em">
                <li style="margin-bottom: 3px;"><b><i>Modeling open-world cognition as on-demand synthesis of probabilistic models.</i></b><br>[<a href="https://arxiv.org/abs/2507.12547">CogSci,
                        2025</a>][<a href="https://underline.io/events/489/sessions/20432/lecture/118365-modeling-open-world-cognition-as-on-demand-synthesis-of-probabilistic-models">Talk @
                        CogSci</a>]


                </li>
                <li>
                    How do people build ad-hoc theories of <i>another agent's mental states</i>? [<a href="https://arxiv.org/abs/2506.16755">ACL Findings, 2025</a>]
                </li>

                <li>
                    How can agents build ad-hoc environment models for <i>planning and action</i>? [<a href="https://arxiv.org/abs/2312.08566">ICLR, 2024</a>]
                </li>





            </ul>
        </div>


        <div class="highlight">
            <h4 style="margin:0em">How do we build more robust and interpretable AI systems that use language?</h4>
            <ul style="padding-left:1em">
                <li>Are current AI systems good at <i>communicating medical information?</i> [<a href="https://arxiv.org/abs/2502.14898">ICML, 2025</a>]

                <li>How should we design AI systems that <i>think with and alongside us?</i> [<a href="https://arxiv.org/abs/2408.03943">Nature HB, 2024</a>]
                </li>

                <li>How do people use AI systems to solve <i>college-level math problems?</i> [<a href="https://arxiv.org/abs/2306.01694">PNAS, 2024</a>]
                </li>

                <li>How do people communicate with <i>each other about abstract reasoning tasks?</i> [<a href="https://arxiv.org/abs/2106.07824">NeurIPS, 2022</a>]
                </li>
            </ul>
        </div>

        <div class="highlight">
            <h4 style="margin:0em">How do people learn new concepts from language? How do people learn new concepts at all?</h4>
            <ul style="padding-left:1em">
                <li>How might we learn <i>new concepts through the process of learning new words?</i> [<a href="https://arxiv.org/abs/2106.11053">ICML, 2021</a>]
                </li>
                <li>How might we use language to <i>predict which abstractions will be useful?</i> [<a href="https://arxiv.org/abs/2310.19791">ICLR, 2024</a>]
                </li>

                <li>Do people <i>change the words they use</i> to reflect concepts they have in mind? [<a href="https://arxiv.org/abs/2205.05666">CogSci, 2023</a>]
                </li>

                <li>How do <i>writing systems</i> change to reflect the structure of a language? <br>[<a href="https://arxiv.org/pdf/2405.06906">CogSci, 2024</a>][<a
                        href="https://jiang.gy/assets/pdf/jiang2025grapheme.pdf">CogSci, 2025</a>]
                </li>

                <br>
                <li>How might we learn <i>new abstract concepts</i> over simpler mental primitives? How can we learn a more complex programming language on top of a simpler one? </i> <br>[<a
                        href="https://dl.acm.org/doi/abs/10.1145/3453483.3454080">PLDI,
                        2021</a>] [<a href="https://arxiv.org/abs/2006.08381">arxiv-extended-version</a>]
                </li>
                <li>How can we learn new abstract concepts â€” <i>much more efficiently? </i> [<a href="https://dl.acm.org/doi/pdf/10.1145/3571234">POPL,
                        2023</a>]
                </li>
            </ul>

        </div>
    </div>




</body>

</html>